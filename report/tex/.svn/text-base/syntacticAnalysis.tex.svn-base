\section{Syntactic Analysis}
The syntactical analysis is done by the parser which generates a \textit{concrete} or \textit{abstract syntax tree} from a token stream. The difference between the concrete and the abstract syntax tree, is that the concrete syntax tree contains all the content from the tokens in the token stream, while the abstract syntax tree only contains the important information. Figure \ref{fig:concreteabstract} is an example of a concrete and an ideal abstract syntax tree, both created from the string "$(x+y)*z$". It is an ideal abstract syntax because it is difficult to remove more information from the tree without removing essential information about the string.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{img/concreteabstract.png}
\caption{An example of a concrete and an abstract syntax tree containing the same information.}
\label{fig:concreteabstract}
\end{figure}

It should be noted that it is also possible, but not necessary, to create an abstract syntax tree from a concrete syntax tree in a later process like the semantic analysis.

The parser creates the syntax tree by referencing to a context free grammar. The parsing can be done using either bottom-up or top-down parsing. Bottom-up parsing looks at the current token in the token stream and tries to match it to a production in the grammar. Top-down  parsing does the exact opposite by looking at the productions in the grammar and tries to match the expected token to the current token in the token stream.

The following is an example of a \textit{LL parser}. An \textit{LL parser} parses the input from \textbf{L}eft to right, using the top-down approach: \textbf{L}eftmost derivation. The parser generates the parsetree from the EBNF showed in Table \ref{tab:parseebnf}.

\begin{table}[H]
\centering
\begin{tabular}{l r l}
Program & $\longrightarrow$ & [TermOp] Term (TermOp Term)*\\
Term & $\longrightarrow$ & INTEGER\\
TermOp & $\longrightarrow$ & PLUS\\
 & $|$ & MINUS\\
\end{tabular}
\caption{A simple EBNF used for an example of a LL parser.}
\label{tab:parseebnf}
\end{table}

This parser is now going to parse the following tokenstream:
\[INTEGER(5) \quad PLUS(+) \quad INTEGER(39) \quad MINUS(-) \quad INTEGER(2)\]

The parser starts with the \textit{Program} production in the EBNF. First it tries to match the production \textit{TermOp} to the first token in the tokenstream. \textit{TermOp} can be either a \textit{PLUS} or \textit{MINUS} token. The first token is an \textit{INTEGER} token and does not match. Therefore the current token does not match the \textit{TermOp} production. But because this production is marked as optional in the EBNF, the parser continues. The parser now tries to match the token to the \textit{Term} production. This production matches an \textit{INTEGER} token like the current token. Because of this, the token is accepted as a \textit{Term} production. The parser continues with this procedure with the rest of the tokens in the token stream. If a needed token does not match the EBNF, or there is unmatched tokens in the token stream when it is done, the parser will produce an error.

It has only been mentioned that the parser tries to match the current token in the stream but it is sometimes necessary to match multiple tokens in the token stream. That is called the lookahead of the parser. A parser with a lookahead of 1 is only able to look at the current token in the stream while a parser with a lookahead of 2 is able to look at the next two tokens in the token stream and so on.

\section{Execution}
The execution can be approached in two different ways:
\begin{description}
\item[Iterative interpretation] is useful if the source language is primitive. In this kind of interpretation the instructions are fetched, analysed and executed one after another. An example of this could be a very simple language that allows for every instruction to be executed one after another, or command languages \cite{commandlanguage}.\\
Iterative interpreters work in a fetch-analyse-execute cycle:\\
\begin{lstlisting}[language=C, caption={Fetch-analyse-execute},label=iteInter]
initialize
do	{
	fetch the next instruction
	analyze this instruction
	execute this instruction
} while (still running);
\end{lstlisting}
The Listing \ref{iteInter} is from the book "Programming Language Processors in Java" which illustrates this cycle very well \cite{plpjava}.

An instruction is first fetched from either the source or sometimes directly by the user (depending on the system), then analysed into its component parts, and finally executed. This is constantly repeated while the system is running.\citep{plpjava}

\item[Recursive interpretation] is necessary if the instructions of the source language consists of separate elements. This means that interpretation of an instruction that has separate elements will interpret the component instructions. The interpreter for a high level language must be recursive, since this allow for more complex instructions, such as conditions and loops.

Interpretation is much slower than using a compiler, and this is why most high level languages uses a compiler instead of an interpreter.

In languages of higher level the commands may contain subcommands, thereby requiring recursive interpreting instead of iterative interpreting. When analysing the commands of a high level language, the subcommands must be analysed as well, recursively. The same applies to the subcommands of these subcommands and so on.\citep{plpjava}
\end{description}